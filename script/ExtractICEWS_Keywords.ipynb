{
 "metadata": {
  "name": "ExtractICEWS_Keywords"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pds\n",
      "from glob import glob\n",
      "import json\n",
      "import sys\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Extract Assault keywords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ass_folder = \"/raid/tskatom/assault_keywords_count/\"\n",
      "files = os.listdir(ass_folder)\n",
      "word_count = {}\n",
      "for f in files:\n",
      "    if os.path.isdir(os.path.join(ass_folder, f)):\n",
      "        continue\n",
      "    with open(os.path.join(ass_folder, f)) as df:\n",
      "        word_json = json.load(df)\n",
      "        for country, w_set in word_json.items():\n",
      "            word_count.setdefault(country, {})\n",
      "            for word, days_set in w_set.items():\n",
      "                word_count[country].setdefault(word, {})\n",
      "                for day, count in days_set.items():\n",
      "                    word_count[country][word].setdefault(day, 0)\n",
      "                    word_count[country][word][day] += count\n",
      "country_words = {}\n",
      "for country in word_count:\n",
      "    country_word = word_count[country]\n",
      "    word_frame = pds.DataFrame(country_word)\n",
      "    word_frame.index = pds.DatetimeIndex(word_frame.index)\n",
      "    country_words[country] = word_frame.resample('W', how='sum').fillna(0)\n",
      "\n",
      "if not os.path.exists(\"/home/tskatom/data/icews_keywords_data/assault\"):\n",
      "    os.mkdir(\"/home/tskatom/data/icews_keywords_data/assault\")\n",
      "for country in country_words:\n",
      "    outfile = \"/home/tskatom/data/icews_keywords_data/assault/%s.csv\" % country\n",
      "    df = country_words[country]\n",
      "    df.to_csv(outfile, sep='\\t', encoding='utf-8')            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Extract Coerce Keywords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ass_folder = \"/raid/tskatom/coerce_keywords_count/\"\n",
      "files = os.listdir(ass_folder)\n",
      "word_count = {}\n",
      "for f in files:\n",
      "    if os.path.isdir(os.path.join(ass_folder, f)):\n",
      "        continue\n",
      "    with open(os.path.join(ass_folder, f)) as df:\n",
      "        word_json = json.load(df)\n",
      "        for country, w_set in word_json.items():\n",
      "            word_count.setdefault(country, {})\n",
      "            for word, days_set in w_set.items():\n",
      "                word_count[country].setdefault(word, {})\n",
      "                for day, count in days_set.items():\n",
      "                    word_count[country][word].setdefault(day, 0)\n",
      "                    word_count[country][word][day] += count\n",
      "country_words = {}\n",
      "for country in word_count:\n",
      "    country_word = word_count[country]\n",
      "    word_frame = pds.DataFrame(country_word)\n",
      "    word_frame.index = pds.DatetimeIndex(word_frame.index)\n",
      "    country_words[country] = word_frame.resample('W', how='sum').fillna(0)\n",
      "\n",
      "if not os.path.exists(\"/home/tskatom/data/icews_keywords_data/coerce/\"):\n",
      "    os.mkdir(\"/home/tskatom/data/icews_keywords_data/coerce/\")\n",
      "for country in country_words:\n",
      "    outfile = \"/home/tskatom/data/icews_keywords_data/coerce/%s.csv\" % country\n",
      "    df = country_words[country]\n",
      "    df.to_csv(outfile, sep='\\t', encoding='utf-8')            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Extract Protest keywords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ass_folder = \"/raid/tskatom/arabia_mouna_keywords_count/\"\n",
      "files = os.listdir(ass_folder)\n",
      "word_count = {}\n",
      "for f in files:\n",
      "    if os.path.isdir(os.path.join(ass_folder, f)):\n",
      "        continue\n",
      "    with open(os.path.join(ass_folder, f)) as df:\n",
      "        word_json = json.load(df)\n",
      "        for country, w_set in word_json.items():\n",
      "            word_count.setdefault(country, {})\n",
      "            for word, days_set in w_set.items():\n",
      "                word_count[country].setdefault(word, {})\n",
      "                for day, count in days_set.items():\n",
      "                    word_count[country][word].setdefault(day, 0)\n",
      "                    word_count[country][word][day] += count\n",
      "country_words = {}\n",
      "for country in word_count:\n",
      "    country_word = word_count[country]\n",
      "    word_frame = pds.DataFrame(country_word)\n",
      "    word_frame.index = pds.DatetimeIndex(word_frame.index)\n",
      "    country_words[country] = word_frame.resample('W', how='sum').fillna(0)\n",
      "\n",
      "if not os.path.exists(\"/home/tskatom/data/icews_keywords_data/protest/\"):\n",
      "    os.mkdir(\"/home/tskatom/data/icews_keywords_data/protest/\")\n",
      "for country in country_words:\n",
      "    outfile = \"/home/tskatom/data/icews_keywords_data/protest/%s.csv\" % country\n",
      "    df = country_words[country]\n",
      "    df.to_csv(outfile, sep='\\t', encoding='utf-8')            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}